{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26bb852a-8773-4091-b82a-edc73e8e0561",
   "metadata": {},
   "source": [
    "# Intro\n",
    " Dieses Jupyter Notebook bietet eine praktische Einführung in OpenCV,\n",
    " und behandelt grundlegende Bildverarbeitungsoperationen und häufige Computer Vision-Aufgaben.\n",
    " Perfekt für Anfänger mit grundlegenden Python-Kenntnissen.\n",
    "\n",
    " Um dieses Notebook auszuführen:\n",
    " 1. Installiere Jupyter: pip install notebook\n",
    " 2. Speichere diese Datei als opencv_intro.ipynb\n",
    " 3. Führe aus: jupyter notebook\n",
    " 4. Öffne die gespeicherte Datei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fddc1c4-3651-4622-8338-aaa21e50079e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zelle 1: Einrichtung und Installation\n",
    "# ==============================\n",
    "# Führe diese Zelle aus, um OpenCV zu installieren und die notwendigen Bibliotheken zu importieren\n",
    "\n",
    "# !pip install opencv-python matplotlib numpy\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"OpenCV version:\", cv2.__version__)\n",
    "print(\"NumPy version:\", np.__version__)\n",
    "\n",
    "# Zelle 2: Was ist OpenCV?\n",
    "# ======================\n",
    "# Informationszelle - nur lesen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48148017-5cd6-4cb0-986b-12dc4cab90d3",
   "metadata": {},
   "source": [
    "# Was ist OpenCV?\n",
    "\n",
    "OpenCV (Open Source Computer Vision Library) ist eine Open-Source-Bibliothek für Computer Vision und \n",
    "maschinelles Lernen. Sie wurde entwickelt, um eine gemeinsame Infrastruktur für Computer-Vision-Anwendungen \n",
    "bereitzustellen und die Nutzung maschineller Wahrnehmung zu beschleunigen.\n",
    "\n",
    "## Was kann man mit OpenCV machen?\n",
    "1. **Bildverarbeitung**: Bilder lesen, schreiben und manipulieren\n",
    "2. **Videoanalyse**: Videostreams verarbeiten und Objekte verfolgen\n",
    "3. **Objekterkennung**: Objekte in Bildern identifizieren (Gesichter, Autos usw.)\n",
    "4. **Bildsegmentierung**: Bild in Regionen aufteilen\n",
    "5. **Merkmalsextraktion**: Schlüsselpunkte und Muster identifizieren\n",
    "6. **Integration von maschinellem Lernen**: Mit ML-Algorithmen arbeiten\n",
    "\n",
    "## Warum ist OpenCV so beliebt?\n",
    "- Es ist kostenlos und Open-Source\n",
    "- Funktioniert auf mehreren Plattformen (Windows, Linux, macOS, Android, iOS)\n",
    "- Unterstützt mehrere Programmiersprachen (Python, C++, Java)\n",
    "- Hat eine große Community für Unterstützung\n",
    "- Hochoptimiert für Echtzeitanwendungen\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7279ba-c6b8-4c17-896b-13055a4a0b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zelle 3: Bilder laden und anzeigen\n",
    "# ====================================\n",
    "# Beginnen wir mit den Grundlagen - das Laden und Anzeigen eines Bildes\n",
    "\n",
    "# Download a sample image first\n",
    "# !wget https://raw.githubusercontent.com/opencv/opencv/master/samples/data/lena.jpg -O sample.jpg\n",
    "\n",
    "# Method 1: Using OpenCV to display an image\n",
    "img = cv2.imread('sample.jpg')  # Replace with your image path if needed\n",
    "\n",
    "# Check if image was loaded successfully\n",
    "if img is None:\n",
    "    print(\"Error: Could not read the image. Check the path.\")\n",
    "else:\n",
    "    print(\"Image shape (height, width, channels):\", img.shape)\n",
    "    \n",
    "    # Display using OpenCV (this won't work in Jupyter, but good to know)\n",
    "    # cv2.imshow('Image', img)\n",
    "    # cv2.waitKey(0)  # Wait until a key is pressed\n",
    "    # cv2.destroyAllWindows()\n",
    "    \n",
    "    # For Jupyter notebooks, we use matplotlib instead\n",
    "    # OpenCV loads images in BGR format, but matplotlib expects RGB\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.title('Sample Image')\n",
    "    plt.axis('off')  # Hide axes\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc11422-cfab-40cb-8eb0-55fe736a6586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zelle 4: Einfache Bilder erstellen\n",
    "# =============================\n",
    "# Lassen Sie uns einige einfache Bilder erstellen, um das Konzept digitaler Bilder zu verstehen\n",
    "\n",
    "# Create a blank black image (height, width, channels)\n",
    "black = np.zeros((300, 300, 3), dtype=np.uint8)\n",
    "\n",
    "# Create a white image\n",
    "white = np.ones((300, 300, 3), dtype=np.uint8) * 255\n",
    "\n",
    "# Create a blue image (remember OpenCV uses BGR)\n",
    "blue = np.zeros((300, 300, 3), dtype=np.uint8)\n",
    "blue[:, :, 0] = 255  # Set the blue channel to maximum\n",
    "\n",
    "# Create a red image\n",
    "red = np.zeros((300, 300, 3), dtype=np.uint8)\n",
    "red[:, :, 2] = 255  # Set the red channel to maximum\n",
    "\n",
    "# Display all images in a grid\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.imshow(black)\n",
    "plt.title('Black Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.imshow(white)\n",
    "plt.title('White Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.imshow(cv2.cvtColor(blue, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Blue Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.imshow(cv2.cvtColor(red, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Red Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2aa8ac3-d82a-4094-b3b2-d515fe8fbfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zelle 5: Grundlegende Zeichenoperationen\n",
    "# ===============================\n",
    "# Lassen Sie uns lernen, wie man Formen auf Bilder zeichnet\n",
    "\n",
    "# Create a blank canvas\n",
    "canvas = np.ones((500, 500, 3), dtype=np.uint8) * 255  # White canvas\n",
    "\n",
    "# Draw a line\n",
    "# Parameters: image, start_point, end_point, color, thickness\n",
    "cv2.line(canvas, (50, 50), (450, 50), (0, 0, 255), 5)  # Red line\n",
    "\n",
    "# Draw a rectangle\n",
    "# Parameters: image, top_left, bottom_right, color, thickness\n",
    "cv2.rectangle(canvas, (100, 100), (400, 300), (0, 255, 0), 3)  # Green rectangle\n",
    "\n",
    "# Draw a filled rectangle\n",
    "cv2.rectangle(canvas, (150, 350), (350, 450), (255, 0, 0), -1)  # Blue filled rectangle\n",
    "\n",
    "# Draw a circle\n",
    "# Parameters: image, center, radius, color, thickness\n",
    "cv2.circle(canvas, (250, 250), 75, (0, 0, 0), 2)  # Black circle\n",
    "\n",
    "# Add text\n",
    "# Parameters: image, text, position, font, scale, color, thickness\n",
    "cv2.putText(canvas, 'OpenCV', (150, 50), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "            1.5, (0, 0, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "# Display the canvas\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(cv2.cvtColor(canvas, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Basic Drawing Operations')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342460ed-d88b-47b1-b47f-ce206ccfde71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zelle 6: Grundlegende Bildoperationen\n",
    "# =============================\n",
    "# Lassen Sie uns einige grundlegende Operationen erkunden, die man auf Bildern durchführen kann\n",
    "\n",
    "# Load an image\n",
    "img = cv2.imread('sample.jpg')\n",
    "\n",
    "if img is None:\n",
    "    print(\"Error: Could not read the image\")\n",
    "else:\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Resize the image\n",
    "    # Parameters: image, (width, height)\n",
    "    resized = cv2.resize(img, (img.shape[1]//2, img.shape[0]//2))\n",
    "    \n",
    "    # Blur the image\n",
    "    # Parameters: image, kernel_size\n",
    "    blurred = cv2.GaussianBlur(img, (15, 15), 0)\n",
    "    \n",
    "    # Display the results\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Original')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.imshow(gray, cmap='gray')\n",
    "    plt.title('Grayscale')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.imshow(cv2.cvtColor(resized, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Resized (50%)')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.imshow(cv2.cvtColor(blurred, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Blurred')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e5b3d5-9519-4441-bb87-7388c81e233e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zelle 7: Bildtransformationen\n",
    "# ============================\n",
    "# Lassen Sie uns einige fortgeschrittenere Bildtransformationen erkunden\n",
    "\n",
    "# Load an image\n",
    "img = cv2.imread('sample.jpg')\n",
    "\n",
    "if img is None:\n",
    "    print(\"Error: Could not read the image\")\n",
    "else:\n",
    "    # Rotate the image\n",
    "    rows, cols = img.shape[:2]\n",
    "    rotation_matrix = cv2.getRotationMatrix2D((cols/2, rows/2), 45, 1)\n",
    "    rotated = cv2.warpAffine(img, rotation_matrix, (cols, rows))\n",
    "    \n",
    "    # Flip the image horizontally\n",
    "    flipped_h = cv2.flip(img, 1)  # 1 for horizontal flip\n",
    "    \n",
    "    # Flip the image vertically\n",
    "    flipped_v = cv2.flip(img, 0)  # 0 for vertical flip\n",
    "    \n",
    "    # Crop the image (using NumPy slicing)\n",
    "    # Format: image[y_start:y_end, x_start:x_end]\n",
    "    center_y, center_x = rows//2, cols//2\n",
    "    size = 100\n",
    "    cropped = img[center_y-size:center_y+size, center_x-size:center_x+size]\n",
    "    \n",
    "    # Display results\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    \n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Original')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.imshow(cv2.cvtColor(rotated, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Rotated 45°')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.imshow(cv2.cvtColor(flipped_h, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Horizontal Flip')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.imshow(cv2.cvtColor(cropped, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Cropped Center')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Zelle 8: Kantenerkennung\n",
    "# =====================\n",
    "# Kantenerkennung ist eine grundlegende Technik in der Computer Vision\n",
    "\n",
    "# Load an image and convert to grayscale\n",
    "img = cv2.imread('sample.jpg')\n",
    "\n",
    "if img is None:\n",
    "    print(\"Error: Could not read the image\")\n",
    "else:\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Canny Edge Detection\n",
    "    # Parameters: image, threshold1, threshold2\n",
    "    edges = cv2.Canny(gray, 100, 200)\n",
    "    \n",
    "    # Sobel Edge Detection (gradient in x-direction)\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=5)\n",
    "    sobelx = cv2.convertScaleAbs(sobelx)\n",
    "    \n",
    "    # Sobel Edge Detection (gradient in y-direction)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=5)\n",
    "    sobely = cv2.convertScaleAbs(sobely)\n",
    "    \n",
    "    # Display results\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Original')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.imshow(edges, cmap='gray')\n",
    "    plt.title('Canny Edges')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.imshow(sobelx, cmap='gray')\n",
    "    plt.title('Sobel X')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.imshow(sobely, cmap='gray')\n",
    "    plt.title('Sobel Y')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9707985a-7c7b-43cf-a4ae-f92bffa7294e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zelle 9: Schwellenwertverfahren (Thresholding)\n",
    "# ===================\n",
    "# Schwellenwertverfahren ist eine Technik, um Objekte vom Hintergrund zu trennen\n",
    "\n",
    "# Load an image and convert to grayscale\n",
    "img = cv2.imread('sample.jpg')\n",
    "\n",
    "if img is None:\n",
    "    print(\"Error: Could not read the image\")\n",
    "else:\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Simple Thresholding\n",
    "    # Parameters: image, threshold_value, max_value, type\n",
    "    ret, thresh1 = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Adaptive Thresholding\n",
    "    # Parameters: image, max_value, adaptive_method, threshold_type, block_size, C\n",
    "    thresh2 = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, \n",
    "                                    cv2.THRESH_BINARY, 11, 2)\n",
    "    \n",
    "    # Otsu's Thresholding\n",
    "    # Automatically determines the optimal threshold value\n",
    "    ret, thresh3 = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # Display results\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.imshow(gray, cmap='gray')\n",
    "    plt.title('Grayscale')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.imshow(thresh1, cmap='gray')\n",
    "    plt.title('Simple Thresholding')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.imshow(thresh2, cmap='gray')\n",
    "    plt.title('Adaptive Thresholding')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.imshow(thresh3, cmap='gray')\n",
    "    plt.title('Otsu Thresholding')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0eeb65-55f5-4865-b87a-bc6d63a0d4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zelle 10: Merkmalserkennung\n",
    "# ========================\n",
    "# Schauen wir uns einige grundlegende Methoden zur Merkmalserkennung an\n",
    "\n",
    "# Load an image\n",
    "img = cv2.imread('sample.jpg')\n",
    "\n",
    "if img is None:\n",
    "    print(\"Error: Could not read the image\")\n",
    "else:\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Harris Corner Detection\n",
    "    gray_float = np.float32(gray)\n",
    "    corners = cv2.cornerHarris(gray_float, blockSize=2, ksize=3, k=0.04)\n",
    "    \n",
    "    # Dilate to mark the corners\n",
    "    corners = cv2.dilate(corners, None)\n",
    "    \n",
    "    # Create a copy of the original image to draw corners on\n",
    "    corner_img = img.copy()\n",
    "    corner_img[corners > 0.01 * corners.max()] = [0, 0, 255]  # Mark in red\n",
    "    \n",
    "    # Shi-Tomasi Corner Detection\n",
    "    corners_st = cv2.goodFeaturesToTrack(gray, maxCorners=50, qualityLevel=0.01, minDistance=10)\n",
    "    \n",
    "    # Create a copy of the original image to draw corners on\n",
    "    corner_img_st = img.copy()\n",
    "    if corners_st is not None:\n",
    "        for corner in corners_st:\n",
    "            x, y = corner.ravel()\n",
    "            cv2.circle(corner_img_st, (int(x), int(y)), 5, (0, 255, 0), -1)\n",
    "    \n",
    "    # Display results\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Original')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(cv2.cvtColor(corner_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Harris Corners')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(cv2.cvtColor(corner_img_st, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Shi-Tomasi Corners')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c21f7f9-6897-46d6-a7d7-a50dc7cfaa6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zelle 11: Konturerkennung\n",
    "# =========================\n",
    "# Konturen sind nützlich für Formanalyse und Objekterkennung/-erkennung\n",
    "\n",
    "# Load an image and convert to grayscale\n",
    "img = cv2.imread('sample.jpg')\n",
    "\n",
    "if img is None:\n",
    "    print(\"Error: Could not read the image\")\n",
    "else:\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply threshold to get a binary image\n",
    "    ret, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Find contours\n",
    "    # Returns: contours (list of contour points), hierarchy\n",
    "    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    print(f\"Number of contours found: {len(contours)}\")\n",
    "    \n",
    "    # Create a copy of the image to draw contours on\n",
    "    contour_img = img.copy()\n",
    "    \n",
    "    # Draw all contours\n",
    "    # Parameters: image, contours, contour_index (-1 for all), color, thickness\n",
    "    cv2.drawContours(contour_img, contours, -1, (0, 255, 0), 2)\n",
    "    \n",
    "    # Create another copy to draw only the 5 largest contours\n",
    "    large_contour_img = img.copy()\n",
    "    \n",
    "    # Sort contours by area and get the 5 largest\n",
    "    sorted_contours = sorted(contours, key=cv2.contourArea, reverse=True)[:5]\n",
    "    \n",
    "    # Draw the 5 largest contours in different colors\n",
    "    colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0), (0, 255, 255)]\n",
    "    \n",
    "    for i, contour in enumerate(sorted_contours):\n",
    "        color = colors[i % len(colors)]\n",
    "        cv2.drawContours(large_contour_img, [contour], -1, color, 3)\n",
    "    \n",
    "    # Display results\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Original')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(cv2.cvtColor(contour_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('All Contours')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(cv2.cvtColor(large_contour_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('5 Largest Contours')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193508ec-c334-4253-b112-fdf72cef8239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zelle 12: Einfache Objekterkennung\n",
    "# ==============================\n",
    "# Implementieren wir eine sehr einfache farbbasierte Objekterkennung\n",
    "\n",
    "# Erstellen Sie eine Funktion zur Erkennung von Objekten anhand der Farbe\n",
    "def detect_color(image, lower_bound, upper_bound):\n",
    "    \"\"\"\n",
    "    Erkennt Objekte eines bestimmten Farbbereichs in einem Bild.\n",
    "    \n",
    "    Args:\n",
    "        image: Eingabebild (BGR-Format)\n",
    "        lower_bound: Untere HSV-Grenzen für die Farbe\n",
    "        upper_bound: Obere HSV-Grenzen für die Farbe\n",
    "        \n",
    "    Returns:\n",
    "        mask: Binäre Maske der erkannten Bereiche\n",
    "        result: Originalbild mit hervorgehobenen erkannten Bereichen\n",
    "    \"\"\"\n",
    "    # Convert to HSV color space\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Create a mask for the specified color range\n",
    "    mask = cv2.inRange(hsv, lower_bound, upper_bound)\n",
    "    \n",
    "    # Find contours in the mask\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Create a copy of the original image\n",
    "    result = image.copy()\n",
    "    \n",
    "    # Draw contours on the original image\n",
    "    cv2.drawContours(result, contours, -1, (0, 255, 0), 2)\n",
    "    \n",
    "    # Draw bounding rectangles around detected objects\n",
    "    for contour in contours:\n",
    "        # Only consider contours with a reasonable size\n",
    "        if cv2.contourArea(contour) > 500:\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            cv2.rectangle(result, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "    \n",
    "    return mask, result\n",
    "\n",
    "# Load a colorful image\n",
    "img = cv2.imread('sample.jpg')\n",
    "\n",
    "if img is None:\n",
    "    print(\"Error: Could not read the image\")\n",
    "else:\n",
    "    # Define color ranges in HSV\n",
    "    # Red is a special case because it wraps around the hue spectrum\n",
    "    lower_red1 = np.array([0, 100, 100])\n",
    "    upper_red1 = np.array([10, 255, 255])\n",
    "    \n",
    "    lower_red2 = np.array([160, 100, 100])\n",
    "    upper_red2 = np.array([180, 255, 255])\n",
    "    \n",
    "    lower_blue = np.array([100, 50, 50])\n",
    "    upper_blue = np.array([130, 255, 255])\n",
    "    \n",
    "    # Convert to HSV\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Detect red (combining two ranges)\n",
    "    mask_red1 = cv2.inRange(hsv, lower_red1, upper_red1)\n",
    "    mask_red2 = cv2.inRange(hsv, lower_red2, upper_red2)\n",
    "    mask_red = cv2.bitwise_or(mask_red1, mask_red2)\n",
    "    \n",
    "    # Detect blue\n",
    "    mask_blue, blue_detected = detect_color(img, lower_blue, upper_blue)\n",
    "    \n",
    "    # Create result for red\n",
    "    red_result = img.copy()\n",
    "    contours, _ = cv2.findContours(mask_red, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cv2.drawContours(red_result, contours, -1, (0, 255, 0), 2)\n",
    "    \n",
    "    for contour in contours:\n",
    "        if cv2.contourArea(contour) > 500:\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            cv2.rectangle(red_result, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "    \n",
    "    # Display results\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Original')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.imshow(mask_red, cmap='gray')\n",
    "    plt.title('Red Mask')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.imshow(cv2.cvtColor(red_result, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Red Detection')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.imshow(cv2.cvtColor(blue_detected, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Blue Detection')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25082bf-5d48-484b-843c-741868a1e22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zelle 13: Grundlagen der Videoverarbeitung\n",
    "# ===============================\n",
    "# Schauen wir uns an, wie man Videos mit OpenCV verarbeitet\n",
    "\n",
    "\"\"\"\n",
    "# Videoverarbeitung mit OpenCV\n",
    "\n",
    "Nachfolgend finden Sie einen Beispielcode, der zeigt, wie man:\n",
    "1. Videos aus einer Datei oder Webcam liest\n",
    "2. Jeden Frame verarbeitet\n",
    "3. Das Ergebnis anzeigt\n",
    "4. Das verarbeitete Video speichert\n",
    "\n",
    "```python\n",
    "import cv2\n",
    "\n",
    "# Open a video file or webcam\n",
    "cap = cv2.VideoCapture('video.mp4')  # Use 0 for webcam\n",
    "\n",
    "# Check if video opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "# Get video properties\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Create a VideoWriter object to save the processed video\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')  # Codec\n",
    "out = cv2.VideoWriter('output.avi', fourcc, fps, (width, height))\n",
    "\n",
    "while cap.isOpened():\n",
    "    # Read a frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        print(\"End of video or error occurred.\")\n",
    "        break\n",
    "    \n",
    "    # Process the frame\n",
    "    # Example: Convert to grayscale, then back to BGR for saving\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    processed = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    # Write the processed frame to the output file\n",
    "    out.write(processed)\n",
    "    \n",
    "    # Display the original and processed frames\n",
    "    cv2.imshow('Original', frame)\n",
    "    cv2.imshow('Processed', processed)\n",
    "    \n",
    "    # Exit if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release everything when done\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "\n",
    "Hinweise für die Arbeit mit Video:\n",
    "- Verwenden Sie `cv2.VideoCapture(0)`, um auf die Webcam zuzugreifen\n",
    "- Die `waitKey`-Verzögerung bestimmt, wie viele Millisekunden jeder Frame angezeigt wird\n",
    "- Kleinere Verzögerung = schnellere Wiedergabe\n",
    "- Für die Echtzeit-Verarbeitung müssen Sie möglicherweise Ihren Code für Geschwindigkeit optimieren\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8401cea6-74b3-4223-8640-33338479901b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zelle 14: Praktische Anwendungen von OpenCV\n",
    "# =========================================\n",
    "# Lassen Sie uns einige praktische Anwendungen diskutieren\n",
    "\n",
    "\"\"\"\n",
    "# Praktische Anwendungen von OpenCV\n",
    "\n",
    "OpenCV ermöglicht eine breite Palette von Computer-Vision-Anwendungen in vielen Branchen:\n",
    "\n",
    "## 1. Gesichtserkennung und -analyse\n",
    "- Gesichtserkennung und -identifikation\n",
    "- Emotionserkennung\n",
    "- Alters- und Geschlechtsschätzung\n",
    "- Erkennung von Gesichtsmerkmalen (Augen, Nase, Mund)\n",
    "\n",
    "## 2. Erweiterte Realität (AR)\n",
    "- Objektverfolgung für AR-Overlays\n",
    "- Markerbasierte AR\n",
    "- Feature-Matching für nahtlose Integration\n",
    "\n",
    "## 3. Medizinische Bildgebung\n",
    "- Analyse medizinischer Bilder\n",
    "- Tumorerkennung\n",
    "- Zellzählung\n",
    "- Verarbeitung medizinischer Scans\n",
    "\n",
    "## 4. Autonome Fahrzeuge\n",
    "- Spurerkennung\n",
    "- Verkehrszeichenerkennung\n",
    "- Fußgängererkennung\n",
    "- Hindernisvermeidung\n",
    "\n",
    "## 5. Industrieautomation\n",
    "- Qualitätskontrolle und Inspektion\n",
    "- Fehlererkennung\n",
    "- Barcode- und QR-Code-Scanning\n",
    "- Roboter-Sichtsysteme\n",
    "\n",
    "## 6. Sicherheit und Überwachung\n",
    "- Bewegungserkennung\n",
    "- Personenverfolgung\n",
    "- Kennzeichenerkennung\n",
    "- Anomalieerkennung\n",
    "\n",
    "## 7. Einzelhandelsanalyse\n",
    "- Kundenzählung\n",
    "- Heatmapping des Ladenverkehrs\n",
    "- Produkterkennung\n",
    "- Regalüberwachung\n",
    "\n",
    "## 8. Landwirtschaft\n",
    "- Erkennung von Pflanzenkrankheiten\n",
    "- Obst-/Früchtezählung und Qualitätsbewertung\n",
    "- Unkrauterkennung\n",
    "- Drohnenbasierte Feldüberwachung\n",
    "\n",
    "## 9. Sportanalyse\n",
    "- Spielerverfolgung\n",
    "- Ballverfolgung\n",
    "- Leistungsanalyse\n",
    "- Automatische Punktestandführung\n",
    "\n",
    "## 10. Dokumentenverarbeitung\n",
    "- OCR (Optische Zeichenerkennung)\n",
    "- Dokumentenscanning\n",
    "- Handschrifterkennung\n",
    "- Formularverarbeitung\n",
    "\n",
    "Diese Anwendungen demonstrieren die Vielseitigkeit und Leistungsfähigkeit der Computer Vision \n",
    "bei der Lösung praktischer Probleme in verschiedenen Bereichen.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07e8018-cb00-4463-aeeb-cd23bcf18288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zelle 15: Fazit und nächste Schritte\n",
    "# =================================\n",
    "# Zusammenfassung und Vorschläge für weiteres Lernen\n",
    "\n",
    "\"\"\"\n",
    "# Fazit und nächste Schritte\n",
    "\n",
    "Herzlichen Glückwunsch! Du hast diese Einführung in OpenCV mit Python abgeschlossen. \n",
    "Du hast gelernt über:\n",
    "\n",
    "- Laden und Anzeigen von Bildern\n",
    "- Grundlegende Bildoperationen und -transformationen\n",
    "- Kantenerkennung und Schwellenwertverfahren\n",
    "- Merkmals- und Konturerkennung\n",
    "- Farbbasierte Objekterkennung\n",
    "- Grundlagen der Videoverarbeitung\n",
    "\n",
    "## Wie geht es weiter:\n",
    "\n",
    "1. **Übe mit deinen eigenen Bildern**\n",
    "   - Wende diese Techniken auf deine eigenen Fotos an\n",
    "   - Experimentiere mit verschiedenen Parametern\n",
    "\n",
    "2. **Erkunde fortgeschrittenere Themen**\n",
    "   - Integration von maschinellem Lernen mit OpenCV\n",
    "   - Objektverfolgung\n",
    "   - 3D-Vision\n",
    "   - Deep Learning mit OpenCV\n",
    "\n",
    "3. **Baue praktische Projekte**\n",
    "   - Gesichtserkennungs- und -identifikationssystem\n",
    "   - Dokumentenscanner\n",
    "   - Objektzähler\n",
    "   - Anwendung für erweiterte Realität\n",
    "\n",
    "4. **Nützliche Ressourcen**\n",
    "   - OpenCV-Dokumentation: https://docs.opencv.org/\n",
    "   - PyImageSearch: https://www.pyimagesearch.com/\n",
    "   - OpenCV-Tutorials: https://opencv-python-tutroals.readthedocs.io/\n",
    "\n",
    "5. **Tritt der Community bei**\n",
    "   - Stack Overflow OpenCV-Tag\n",
    "   - Computer Vision Subreddit\n",
    "   - OpenCV-Forum\n",
    "\n",
    "Denk daran, dass der beste Weg, Computer Vision zu lernen, durch praktische Anwendung führt. \n",
    "Fang klein an, experimentiere häufig und stelle dich nach und nach komplexeren Herausforderungen!\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
